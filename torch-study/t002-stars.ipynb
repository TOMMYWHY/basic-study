{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/pulsar_stars.csv\",nrows=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Mean of the integrated profile  \\\n0                          140.562500   \n1                          102.507812   \n2                          103.015625   \n3                          136.750000   \n4                           88.726562   \n...                               ...   \n3995                       108.421875   \n3996                       101.898438   \n3997                       112.976562   \n3998                        99.515625   \n3999                       115.578125   \n\n       Standard deviation of the integrated profile  \\\n0                                         55.683782   \n1                                         58.882430   \n2                                         39.341649   \n3                                         57.178449   \n4                                         40.672225   \n...                                             ...   \n3995                                      49.875252   \n3996                                      50.420240   \n3997                                      46.050154   \n3998                                      47.455733   \n3999                                      45.820405   \n\n       Excess kurtosis of the integrated profile  \\\n0                                      -0.234571   \n1                                       0.465318   \n2                                       0.323328   \n3                                      -0.068415   \n4                                       0.600866   \n...                                          ...   \n3995                                    0.356194   \n3996                                    0.461758   \n3997                                    0.458158   \n3998                                    0.451288   \n3999                                    0.383154   \n\n       Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n0                               -0.699648                   3.199833   \n1                               -0.515088                   1.677258   \n2                                1.051164                   3.121237   \n3                               -0.636238                   3.642977   \n4                                1.123492                   1.178930   \n...                                   ...                        ...   \n3995                             0.140122                  11.224916   \n3996                             0.376136                   3.197324   \n3997                             0.435297                   3.989130   \n3998                             0.465505                  14.775084   \n3999                             0.266933                   7.191472   \n\n       Standard deviation of the DM-SNR curve  \\\n0                                   19.110426   \n1                                   14.860146   \n2                                   21.744669   \n3                                   20.959280   \n4                                   11.468720   \n...                                       ...   \n3995                                43.600214   \n3996                                23.872246   \n3997                                22.797107   \n3998                                48.659888   \n3999                                31.445434   \n\n       Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n0                                 7.975532                      74.242225   \n1                                10.576487                     127.393580   \n2                                 7.735822                      63.171909   \n3                                 6.896499                      53.593661   \n4                                14.269573                     252.567306   \n...                                    ...                            ...   \n3995                              3.942828                      14.564314   \n3996                              8.232433                      70.314547   \n3997                              6.788768                      50.696445   \n3998                              3.245646                       9.195834   \n3999                              4.817610                      23.619603   \n\n      target_class  \n0                0  \n1                0  \n2                0  \n3                0  \n4                0  \n...            ...  \n3995             0  \n3996             0  \n3997             0  \n3998             0  \n3999             0  \n\n[4000 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean of the integrated profile</th>\n      <th>Standard deviation of the integrated profile</th>\n      <th>Excess kurtosis of the integrated profile</th>\n      <th>Skewness of the integrated profile</th>\n      <th>Mean of the DM-SNR curve</th>\n      <th>Standard deviation of the DM-SNR curve</th>\n      <th>Excess kurtosis of the DM-SNR curve</th>\n      <th>Skewness of the DM-SNR curve</th>\n      <th>target_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>140.562500</td>\n      <td>55.683782</td>\n      <td>-0.234571</td>\n      <td>-0.699648</td>\n      <td>3.199833</td>\n      <td>19.110426</td>\n      <td>7.975532</td>\n      <td>74.242225</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>108.421875</td>\n      <td>49.875252</td>\n      <td>0.356194</td>\n      <td>0.140122</td>\n      <td>11.224916</td>\n      <td>43.600214</td>\n      <td>3.942828</td>\n      <td>14.564314</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>101.898438</td>\n      <td>50.420240</td>\n      <td>0.461758</td>\n      <td>0.376136</td>\n      <td>3.197324</td>\n      <td>23.872246</td>\n      <td>8.232433</td>\n      <td>70.314547</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>112.976562</td>\n      <td>46.050154</td>\n      <td>0.458158</td>\n      <td>0.435297</td>\n      <td>3.989130</td>\n      <td>22.797107</td>\n      <td>6.788768</td>\n      <td>50.696445</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>99.515625</td>\n      <td>47.455733</td>\n      <td>0.451288</td>\n      <td>0.465505</td>\n      <td>14.775084</td>\n      <td>48.659888</td>\n      <td>3.245646</td>\n      <td>9.195834</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>115.578125</td>\n      <td>45.820405</td>\n      <td>0.383154</td>\n      <td>0.266933</td>\n      <td>7.191472</td>\n      <td>31.445434</td>\n      <td>4.817610</td>\n      <td>23.619603</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all=df.iloc[:,-1]\n",
    "X_all = df.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4000, 8)"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all,y_all,test_size =0.2, random_state = 0, stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler = StandardScaler()\n",
    "X_train = standardScaler.fit_transform(X_train)\n",
    "X_test = standardScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "8"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "X_train[0]\n",
    "X_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 0, 0, ..., 0, 0, 1])"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loss: tensor(1441.3431, dtype=torch.float64, grad_fn=<MeanBackward0>)\nloss: tensor(6.4783, dtype=torch.float64, grad_fn=<MeanBackward0>)\nloss: tensor(4.0745, dtype=torch.float64, grad_fn=<MeanBackward0>)\nloss: tensor(3.1065, dtype=torch.float64, grad_fn=<MeanBackward0>)\nloss: tensor(2.5945, dtype=torch.float64, grad_fn=<MeanBackward0>)\nloss: tensor(2.2708, dtype=torch.float64, grad_fn=<MeanBackward0>)\nloss: tensor(2.0406, dtype=torch.float64, grad_fn=<MeanBackward0>)\nloss: tensor(1.8652, dtype=torch.float64, grad_fn=<MeanBackward0>)\nloss: tensor(1.7208, dtype=torch.float64, grad_fn=<MeanBackward0>)\nloss: tensor(1.6013, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
    }
   ],
   "source": [
    "x=torch.tensor(X_train,dtype=float)\n",
    "y=torch.tensor(y_train.values,dtype=float)\n",
    "\n",
    "weights=torch.randn((X_train.shape[-1],128),dtype=float,requires_grad=True)\n",
    "biases=torch.randn(128,dtype=float,requires_grad=True)\n",
    "weights2=torch.randn((128,1),dtype=float,requires_grad=True)\n",
    "biases2=torch.randn(1,dtype=float,requires_grad=True)\n",
    "\n",
    "learning_rate=0.001\n",
    "losses=[]\n",
    "\n",
    "for i in range(1000):\n",
    "    hidden=x.mm(weights)+biases # ax+b\n",
    "    hidden=torch.relu(hidden)\n",
    "    predictions=hidden.mm(weights2)+biases2\n",
    "    \n",
    "    loss=torch.mean((predictions-y)**2)\n",
    "    losses.append(loss.data.numpy())\n",
    "\n",
    "    if i% 100==0:\n",
    "        print('loss:',loss)\n",
    "    loss.backward()\n",
    "\n",
    "    weights.data.add_(-learning_rate*weights.grad.data)\n",
    "    biases.data.add_(-learning_rate*biases.grad.data)\n",
    "    weights2.data.add_(-learning_rate*weights2.grad.data)\n",
    "    biases2.data.add_(-learning_rate*biases2.grad.data)\n",
    "\n",
    "    weights.grad.data.zero_()\n",
    "    biases.grad.data.zero_()\n",
    "    weights2.grad.data.zero_()\n",
    "    biases2.grad.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0., 0., 0.,  ..., 0., 0., 1.], dtype=torch.float64)"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "x\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitpython36conda3fbbdad0e7094e8da5a2f81a42cd6956",
   "display_name": "Python 3.6.10 64-bit ('python36': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}